

# [How is data maintained?](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlHowDataMaintain.html)
- The Cassandra write process stores data in files called SSTables. SSTables are immutable. Instead of overwriting existing rows with inserts or updates, Cassandra writes new timestamped versions of the inserted or updated data in new SSTables. Cassandra does not perform deletes by removing the deleted data: instead, Cassandra marks it with `tombstones.(묘석,묘비)`

카산드라 쓰기 프로세스는 SSTABles라는 파일에 데이터를 저장한다. SSTABle은 불변이다. 삽입 또는 업데이트로 `기존 행을 덮어쓰는 대신,` Cassandra는 (삽입되거나 업데이트된 데이터의 / `새로운 타임스탬프 버전을) 새로운 SSTABle에 기록한다.` Cassandra는 삭제된 데이터를 제거하여 삭제를 수행하지 않는다. 대신, `Cassandra는 삭제된 데이터를 비석으로 표시한다.`


- Over time, Cassandra may write many versions of a row in different SSTables. Each version may have a unique set of columns / stored with a different timestamp. As SSTables `accumulate(모으다, 축적하다),` the distribution of data can require accessing more and more SSTables to `retrieve(검색하다)` a complete row.

시간이 지남에 따라, Cassandra는 다른 SSTABle에 행의 많은 버전을 쓸 수 있다. 각 버전에는 다른 타임스탬프와 함께 저장된 열 집합이 있을 수 있다. `SSTABles가 누적됨에 따라,` 데이터의 분포는 전체 행을 검색하기 위해 `점점 더 많은 SSTABle에 접근해야 할 수 있다.`


- To keep the database healthy, Cassandra `periodically(주기적으로)` merges SSTables and discards old data. This process is called compaction.
데이터베이스를 건강하게 유지하기 위해 Cassandra는 `SSTABle을 주기적으로 병합하고 오래된 데이터를 삭제한다.` 이 과정을 `압축` 이라고 한다.


## Compaction ; SSTables을 주기적으로 병합 & 오래된 데이터 삭제 과정

- Compaction works on a collection of SSTables. From these SSTables, compaction collects all versions of each unique row and assembles one complete row, using the most up-to-date version (by timestamp) of each of the row's columns.

Compaction은 SSTABles 모음에서 작동한다. 이러한 SSTABle에서, Compaction은 각 고유 행의 모든 버전을 수집하고 / 각 행 열의 최신 버전(타임스탬프 기준)을 사용하여 /하나의 완전한 행을 조립한다.

- The merge process is performant((of technology, etc.) working in an effective way), because rows are sorted by partition key within each SSTable, and the merge process does not use random I/O.
The new versions of each row is written to a new SSTable. The old versions, along with any rows that are ready for deletion, are left in the old SSTables, and are deleted as soon as `pending(보류중인, 미결인, 곧있을)` reads are completed.

각 SSTable 내에서 행이 파티션 키별로 정렬되고, 병합 프로세스에서 랜덤 I/O를 사용하지 않기 때문에 병합 프로세스는 수행적이다.
각 행의 새로운 버전은 새로운 SSTable에 기록된다. 삭제 준비가 된 행과 함께 이전 버전은 이전 SSTABLE에 남아 있으며, 보류 중인 읽기가 완료되는 즉시 삭제된다.

![image](https://user-images.githubusercontent.com/55946791/113569192-09714b00-964d-11eb-8470-7938ef0da061.png)



- Compaction causes a temporary `spike(증가)` in disk space usage and disk I/O // while old and new SSTables co-exist.
As it completes, compaction `frees up(확보하다)` disk space occupied by old SSTables.

Compaction은 오래된 SSTABle과 새로운 SSTABle이 공존하는 동안 // 디스크 공간 사용과 디스크 I/O의 일시적인 증가를 야기한다. 그것이 완성되면, 압축은 오래된 SSTABle이 점유한 디스크 공간을 확보한다.


- It improves read performance by incrementally replacing old SSTables with compacted SSTables. Cassandra can read data directly from the new SSTable even before it finishes writing, instead of waiting for the entire compaction process to finish.

기존 SSTABLE을 압축된 SSTABLE로 증분 교체하여 읽기 성능을 향상시킨다. 카산드라는 전체 압축 과정이 끝나기를 기다리는 대신, 쓰기가 끝나기도 전에 새로운 SSTable에서 직접 데이터를 읽을 수 있다.


- As Cassandra processes writes and reads, it replaces the old SSTables with new SSTables in the page cache. The process of caching the new SSTable, while directing reads away from the old one, is incremental — it does not cause a the dramatic cache miss. Cassandra provides predictable high performance even under heavy load.

카산드라가 쓰기 및 읽기를 처리함에 따라 기존의 SSTABle을 페이지 캐시에 있는 새로운 SSTABle로 대체한다. 새로운 SSTable을 캐슁하는 프로세스는 이전 SSTable을 벗어나도록 지시하는 동시에 증분적이다. 이는 극적인 캐시 미스(cache miss) 카산드라는 과부하에서도 예측 가능한 고성능을 제공한다.

## Compaction strategies
- Cassandra supports different compaction strategies, which control how which SSTables are chosen for compaction, and how the compacted rows are sorted into new SSTables. Each strategy has its own strengths. The sections that follow explain each of Cassandra's compaction strategies.

Although each of the following sections starts with a `generalized(일반적인)` recommendation, many factors complicate the choice of a compaction strategy. See Which compaction strategy is best?.

Cassandra는 / 어떤 SSStables가 압축을 위해 선택되었는지, 그리고 압축된 행이 새로운 SSStables로 정렬되는 방법을 제어하는 / 다양한 압축 전략을 지원합니다. 각 전략에는 고유의 강점이 있습니다. 다음 절에서는 카산드라의 압축 전략을 각각 설명합니다.

다음 각 절은 일반적인 권장 사항으로 시작하지만, 많은 요인들이 압축 전략의 선택을 복잡하게 만든다. 어떤 압축 전략이 가장 좋은지 참조하십시오.

### SizeTieredCompactionStrategy (STCS)
- Recommended for write-intensive(집중적인) workloads.The SizeTieredCompactionStrategy (STCS) initiates(개시하게 되다, 시작하다) compaction when Cassandra has `accumulated(모으다, 축적하다)` a set number (default: 4) of similar-sized SSTables.
STCS merges these SSTables into one larger SSTable. As these larger SSTables accumulate, STCS merges these into even larger SSTables. At `any given time(언제든지),` several SSTables of varying sizes are present.

쓰기 집약적인 워크로드에 권장됩니다.Size Tiered Compaction Strategy(STCS)는 Cassandra가 설정된 번호(기본값: 4)의 유사한 크기 SSStables를 누적했을 때 압축을 시작합니다.
STCS는 이러한 SSStable을 하나의 더 큰 SSStable로 병합합니다. 이렇게 큰 SS Stables가 축적되면, STCS는 이것을 훨씬 더 큰 SS Stables로 병합합니다. 언제든지 다양한 크기의 SSStables가 있습니다.


Size tiered compaction after many inserts
![image](https://user-images.githubusercontent.com/55946791/113569601-bcda3f80-964d-11eb-92a2-1438f9bba8e7.png)


- While STCS works well to compact a write-intensive workload, it makes reads slower because the merge-by-size process does not group data by rows.
This makes it more likely that versions of a particular row may be spread over many SSTables. Also, STCS does not evict deleted data predictably because its trigger for compaction is SSTable size, and SSTables might not grow quickly enough to merge and evict old data.

`STC는 쓰기 집약적인 워크로드를 압축하는 데 잘 작동하지만,` 크기별 병합 프로세스에서 행별로 데이터를 그룹화하지 않기 때문에 `읽기 속도가 느려집니다.`
따라서 특정 행의 버전이 많은 SSStables에 분산될 가능성이 더 높습니다. 또한, STCS는 압축에 대한 트리거가 SSTable 크기이고 SSStables가 오래된 데이터를 병합하고 제거할 만큼 빠르게 증가하지 않을 수 있기 때문에 삭제된 데이터를 예측 가능한 방식으로 제거하지 않습니다.


- As the largest SSTables grow in size, the amount of disk space needed for both the new and old SSTables simultaneously(동시에) during STCS compaction can outstrip(앞지르다, 능가하다) a typical amount of disk space on a node.

가장 큰 SSStables의 크기가 커짐에 따라, STCs 압축 중에 새로운 SSStables와 이전 SSStables에 동시에 필요한 디스크 공간의 양이 노드의 일반적인 디스크 공간을 초과할 수 있습니다.

- Pros: Compacts `write-intensive(집중적인, 집약적인)` workload very well.
Cons: Can hold onto `stale(오래된)` data too long. Amount of memory needed increases over time.
`찬성: 쓰기 집약적인 워크로드를 매우 잘 압축합니다.`
`반대: 오래된 데이터를 너무 오래 보유할 수 있습니다. 필요한 메모리 양은 시간이 지남에 따라 증가합니다.`

### LeveledCompactionStrategy (LCS)

- Recommended for read-intensive workloads.
The LeveledCompactionStrategy (LCS) `alleviates(완화하다)` some of the read `operation(작업)` issues with STCS. This strategy works with a series of levels. First, data in memtables is flushed to SSTables in the first level (L0). LCS compaction merges these first SSTables with larger SSTables in level L1.

`읽기 집약적인 워크로드에 추천합니다.`
LCS(Leveled Compaction Strategy)는 STCS의 일부 읽기 작업 문제를 완화합니다. 이 전략은 일련의 수준에서 작동합니다. 먼저, memtable의 데이터는 첫 번째 수준(L0)의 SSTable에 플러시됩니다. LCS 압축은 첫 번째 SSTables와 L1 수준의 더 큰 SSTables를 병합합니다.


- Leveled compaction — adding SSTables
![image](https://user-images.githubusercontent.com/55946791/113569982-60c3eb00-964e-11eb-908a-de1e095bb882.png)

- The SSTables in levels greater than L1 are merged into SSTables with a size greater than or equal to sstable_size_in_mb (default: 160 MB). If a L1 SSTable stores data of a partition that is larger than L2, LCS moves the SSTable past L2 to the next level up.

L1보다 큰 수준의 SSTables는 sstable_size_in_mb보다 크거나 같은 크기의 SSTables로 병합됩니다(기본값: 160MB). L1 SSTable이 L2보다 큰 파티션의 데이터를 저장하는 경우 LCS는 SSTable을 L2를 지나 다음 수준 위로 이동합니다.


- Leveled compaction after many inserts
![image](https://user-images.githubusercontent.com/55946791/113570000-67eaf900-964e-11eb-9f9e-d433c7db691f.png)



- In each of the levels above L0, LCS creates SSTables that are about the same size. Each level is 10X the size of the last level, so level L1 has 10X as many SSTables as L0, and level L2 has 100X as many. If the result of the compaction is more than 10 SSTables in level L1, the excess SSTables are moved to level L2.

L0 위의 각 수준에서 LCS는 크기가 거의 같은 SS 테이블을 생성합니다. 각 레벨은 마지막 레벨보다 10배 크기 때문에 레벨 L1은 SS 테이블 수가 L0보다 10배, 레벨 L2는 100배 더 많습니다. 압축 결과가 L1 수준에서 SSTables 10개 이상이면 초과 SSTables는 L2 수준으로 이동한다.

- The LCS compaction process guarantees / that the SSTables within each level starting with L1 have `non-overlapping(non-중복된)` data. 
For many reads, this process enables Cassandra to `retrieve(검색하다)` all the required data from only one or two SSTables. In fact, 90% of all reads can be satisfied from one SSTable. 
Since LCS does not compact L0 tables, however, resource-intensive reads involving many L0 SSTables may still occur.

LCS 압축 프로세스는 / L1로 시작하는 각 수준 내의 SSTables에 겹치지 않는 데이터가 있음을 보장합니다. 
많은 읽기의 경우 이 프로세스를 통해 Cassandra는 하나 또는 두 개의 SSTables에서 필요한 모든 데이터를 검색할 수 있습니다. 실제로 전체 읽기 중 90%는 하나의 SST 테이블에서 충족할 수 있습니다. 
그러나 LCS는 L0 테이블을 압축하지 않기 때문에 많은 L0 SS 테이블을 포함하는 리소스 집약적인 읽기가 여전히 발생할 수 있습니다.

- At levels beyond L0, LCS requires less disk space for compacting — generally, 10X the fixed size of the SSTable. 
`Obsolete(더이상 쓸모없는)` data is evicted more often, so deleted data uses smaller `portions(부분)` of the SSTables on disk. 
However, LCS compaction operations take place more often and place more I/O burden on the node. For write-intensive workloads, the payoff of using this strategy is generally not worth the performance loss to I/O operations. 
In many cases, tests of LCS-configured tables reveal I/O saturation on writes and compactions.

L0을 초과하는 수준에서 LCS는 압축할 디스크 공간이 적게 필요합니다. 일반적으로 SST 테이블의 고정 크기보다 10배 더 작습니다. 
사용되지 않는 데이터는 더 자주 제거되므로 삭제된 데이터는 디스크의 SSTables에서 더 작은 부분을 사용합니다. 
그러나 LCS 압축 작업은 더 자주 수행되고 노드에 더 많은 I/O 부담을 줍니다. 쓰기 집약적인 워크로드의 경우 일반적으로 이 전략을 사용하면 I/O 작업에 따른 성능 손실의 가치가 없습니다. 
대부분의 경우 LCS 구성 테이블의 테스트에서는 쓰기 및 압축에 대한 I/O 포화도가 표시됩니다.


- Note: Cassandra bypasses compaction operations when bootstrapping a new node using LCS into a cluster. The original data is moved directly to the correct level because there is no existing data, so no partition overlap per level is present. For more information, see Apache Cassandra 2.2 - Bootstrapping Performance Improvements for Leveled Compaction.

참고: Cassandra는 LCS를 사용하여 새 노드를 클러스터에 부트스트랩할 때 압축 작업을 바이패스합니다. 기존 데이터가 없으므로 수준당 파티션 겹침이 없으므로 원래 데이터가 올바른 수준으로 직접 이동됩니다. 자세한 내용은 Apache Cassandra 2.2 - Leveled Compaction의 Bootstrap 성능 향상을 참조하십시오.

- Pros: Disk requirements are easier to predict. Read operation latency is more predictable. Stale data is evicted more frequently.
Cons: Much higher I/O utilization impacting operation latency

`찬성: 디스크 요구 사항을 예측하기가 더 쉽습니다. 읽기 작업 지연 시간을 더 쉽게 예측할 수 있습니다. 오래된 데이터는 더 자주 제거된다.`
`반대: 훨씬 높은 I/O 활용률이 작업 지연 시간에 영향을 미침`




### TimeWindowCompactionStrategy (TWCS)

- Recommended for time series and expiring 
TTL workloads.The TimeWindowCompactionStrategy (TWCS) is similar to DTCS with simpler settings. TWCS groups SSTables using a series of time windows. During compaction, TWCS applies STCS to uncompacted SSTables in the most recent time window. 
At the end of a time window, TWCS compacts all SSTables that fall into that time window into a single SSTable based on the SSTable maximum timestamp. 
Once the major compaction for a time window is completed, no further compaction of the data will ever occur. The process starts over with the SSTables written in the next time window.

시계열 및 TTL 워크로드 만료에 권장됩니다.
TWCS(Time Window Compaction Strategy)는 단순한 설정의 DTC와 유사합니다. `TWCS는 일련의 시간 창을 사용하여 SSTable을 그룹화합니다.` 압축 중에 TWCS는 가장 최근의 시간 창에서 압축되지 않은 SSTables에 STCS를 적용합니다. 
시간 창의 끝에서, TWCS는 해당 시간 창에 속하는 모든 SSTables를 `SSTable 최대 타임스탬프를 기준으로 단일 SSTable로 압축합니다.` 
시간 창의 주요 압축이 완료되면 데이터를 더 이상 압축하지 않습니다. 프로세스는 다음 시간 창에 작성된 SSTables로 다시 시작됩니다.

![image](https://user-images.githubusercontent.com/55946791/113571023-7df9b900-9650-11eb-8f7f-d28adb3eef13.png)



- As the figure shows, from 10 AM to 11 AM, the memtables are flushed from memory into 100MB SSTables. 
These SSTables are compacted into larger SSTables using STCS. At 11 AM, all these SSTables are compacted into a single SSTable, and never compacted again by TWCS. 
At 12 NOON, the new SSTables created between 11 AM and 12 NOON are compacted using STCS, and at the end of the time window the TWCS compaction repeats. 
Notice that each TWCS time window contains varying amounts of data.

그림에서 알 수 있듯이 오전 10시부터 오전 11시까지, memtable은 메모리에서 100MB SS Stables로 플러시됩니다. 
이러한 SSTables는 STCS를 사용하여 더 큰 SSTables로 압축됩니다. 오전 11시에 이 모든 SSTables는 단일 SSTable로 압축되고 TWCS에 의해 다시 압축되지 않는다. 
12시, 오전 11시에서 12시 사이에 생성된 새로운 SSTables는 STCS를 사용하여 압축되며, 시간 창의 끝에 TWCS 압축이 반복된다. 
각 TWCS 시간 창에는 다양한 양의 데이터가 포함되어 있는것을 주목하세요.

- Note: For an animated explanation, see the Datastax Academy Time Window Compaction Strategy video.

The TWCS configuration has two main property settings:
    - compaction_window_unit: time unit used to define the window size (milliseconds, seconds, hours, and so on)
    - compaction_window_size: how many units per window (1,2,3, and so on)

TWCS 구성에는 두 가지 기본 속성 설정이 있습니다.
    - compaction_window_unit: 창 크기를 정의할 때 사용하는 시간 단위(초, 초, 시간 등)
    - compaction_window_size : 창당 단위 수(1,2,3 등)

The configuration for the above example: compaction_window_unit = ‘minutes’,compaction_window_size = 60
위의 예에 대한 구성: compaction_window_unit = '분', compaction_window_size = 60

- Pros: Used for time series data, stored in tables that use the default TTL for all data. Simpler configuration than that of DTCS.
Cons: Not appropriate if `out-of-sequence(순서가 엉망으로)` time data is required, since SSTables will not compact as well.
Also, not appropriate for data without a TTL, as(~하므로) storage will grow without bound. Less fine-tuned configuration is possible than with DTCS.


찬성: 모든 데이터에 대해 `기본 TTL을 사용하는 / 테이블에 저장된 series 데이터에 사용됩니다.` DTC의 구성보다 간단한 구성.
반대: SSTables도 압축되지 않기 때문에 시퀀스를 벗어난 시간 데이터가 필요한 경우에는 적합하지 않습니다.
또한 스토리지가 제한 없이 증가하므로 TTL이 없는 데이터에는 적합하지 않습니다. DTC에 비해 미세 조정이 덜 가능한 구성입니다.



### DateTieredCompactionStrategy (DTCS)
Deprecated in Cassandra 3.0.8/3.8.

- The DateTieredCompactionStrategy (DTCS) is similar to STCS. But instead of compacting based on SSTable size, DTCS compacts based on SSTable age. (Each column in an SSTable is marked with the timestamp at write time. As the age of an SSTable, DTCS uses the oldest (minimum) timestamp of any column the SSTable contains.)

날짜 계층화된 압축 전략(DateTiered Compact Strategy, VERSE)은 STCS와 유사하다. 그러나 DSTable 크기를 기준으로 압축하는 대신 DSTable 연령을 기준으로 압축합니다. (SSTable의 각 열은 쓰기 시 타임스탬프로 표시됩니다. DST 테이블의 시대로서, DTC는 SST 테이블에 포함된 열 중 가장 오래된(최소) 타임스탬프를 사용합니다.)

- Configuring the DTCS time window ensures that new and old data are not mixed in merged SSTables. In fact, using Time-To-Live (TTL) timestamps, DTCS can eject whole SSTables containing expired data. This strategy often generates similar-sized SSTables if time series data is ingested at a steady rate.

DTC 시간 창을 구성하면 새 데이터와 기존 데이터가 병합된 SSTables에서 혼합되지 않습니다. 실제로, TTL(Time-To-Live) 타임스탬프를 사용하여, DTC는 만료된 데이터가 포함된 전체 SSTables를 꺼낼 수 있습니다. 이 전략은 시계열 데이터를 일정한 속도로 섭취하는 경우 유사한 크기의 SSTables를 생성하는 경우가 많다.

- DTCS compacts SSTables into larger tables, as with STCS, when the system accumulates a configurable number of SSTables within a configurable time interval. However, DTCS skips compacting SSTables that reach a configurable age. This logic reduces the number of times data is rewritten. Queries that ask for data in a particular last time interval, such as an hour, can be executed very efficiently on DTCS-compacted SSTables (particularly if the requested time interval is coordinated with the configured interval for compaction).

구성 가능한 시간 간격 내에 구성 가능한 수의 SSTables가 누적되면 STCS와 같이 SSTables를 더 큰 테이블로 압축합니다. 그러나 구성 가능 연령에 도달한 DSTables 압축은 생략합니다. 이 논리는 데이터를 다시 쓰는 횟수를 줄여줍니다. 특정 마지막 간격(예: 한 시간)에 데이터를 요청하는 쿼리는 매우 효율적으로 DTC 압축 SSTables에서 실행될 수 있습니다(특히 요청한 시간 간격이 압축에 대해 구성된 간격으로 조정된 경우).

- One use case that can cause difficulty with this strategy is out-of-sequence writing. For example, an operation that writes a timestamped record with a timestamp outside the current time window. Read repairs can inject out-of-sequence timestamps, so be sure to turn off read repairs when using DTCS. For more information, see DateTieredCompactionStrategy: Notes from the Field.

이 전략에서 어려움을 야기할 수 있는 하나의 사용 사례는 순서 외 쓰기이다. 예를 들어, 현재 시간 창 외부에 타임스탬프를 사용하여 타임스탬프 레코드를 쓰는 작업입니다. 읽기 수리는 시퀀스를 벗어난 타임스탬프를 주입할 수 있으므로, DTC를 사용할 때는 읽기 수리의 전원을 끄십시오. 자세한 내용은 날짜 계층화된 압축 전략: 필드의 메모입니다.

- Pros: Specifically designed for time series data, stored in tables that use the default TTL. DTCS is a better choice when fine-tuning is required to meet space-related SLAs.
Cons: Insertion of records out of time sequence (by repairs or hint replaying) can increase latency or cause errors. In some cases, it may be necessary to turn off read repair and carefully test and control the use of TIMESTAMP options in BATCH, DELETE, INSERT and UPDATE CQL commands.

찬성: 타임 시리즈 데이터를 위해 특별히 설계되었으며, 기본 TTL을 사용하는 테이블에 저장됩니다. 공간 관련 SLA를 충족하기 위해 미세 조정이 필요한 경우에는 DTC를 선택하는 것이 좋습니다.
반대: 복구 또는 힌트 재생을 통해 시간 범위를 벗어난 레코드를 삽입하면 대기 시간이 길어지거나 오류가 발생할 수 있습니다. 경우에 따라 읽기 복구를 끄고 BATCH, DELETE, INSERT 및 UPDATE CQL 명령에서 타임스탬프 옵션을 신중하게 테스트하고 사용해야 할 수도 있습니다.

---

## Which compaction strategy is best?

To implement(구현하다) the best compaction strategy:

1. Review your application's requirements.
2. Configure the table to use the most appropriate strategy.
3. Test the compaction strategies against your data.
The following questions are based on the experiences of Cassandra developers and users with the strategies described above.

1. 애플리케이션의 요구 사항을 검토합니다.
2. 가장 적절한 전략을 사용하도록 테이블을 구성합니다.
3. 압축 전략을 데이터에 대해 테스트합니다.
다음 질문은 위에서 설명한 전략을 가진 카산드라 개발자 및 사용자의 경험을 바탕으로 합니다.

### Does your table process time series data?
If so, your best choices are `TWCS or DTCS.` For details, read the descriptions on this page.
If your table is not `focused on time series data,` the choice becomes more complicated. The following questions introduce other considerations that may guide your choice.

### Does your table handle more reads than writes, or more writes than reads?
`LCS` is a good choice if your table processes twice as `many reads` as writes or more – especially randomized reads. 
If the proportion(비율) of reads to writes is closer, the performance hit exacted by LCS may not be worth the benefit. Be aware that LCS can be quickly `overwhelmed(압도된)` by a high volume of writes.

LCS는 쓰기 또는 쓰기 읽기보다 두 배 이상 많은 읽기(특히 랜덤 읽기)를 처리할 경우 좋은 선택입니다. 
쓰기 읽기 대 쓰기 비율이 더 가까우면 LCS에 의해 정확한 성능을 얻을 가치가 없을 수 있습니다. LCS는 대량의 쓰기로 인해 빠르게 제압될 수 있습니다.

### Does the data in your table change often?
One advantage of `LCS` is that it `keeps related data in a small set of SSTables.` If your data is immutable or not subject to frequent upserts, STCS accomplishes the same type of grouping without the LCS performance hit.

LCS의 한 가지 장점은 관련 데이터를 작은 SS 테이블 집합에 보관한다는 것입니다. 데이터가 불변하거나 자주 upsert되지 않는 경우, STCS는 LCS 성능 적중 없이 동일한 유형의 그룹화를 수행합니다.
upsert ; 업데이트시 만족하는 로우가 있으면 업데이트, 아니면 인서트

### Do you require predictable levels of read and write activity?
LCS keeps the SSTables within predictable sizes and numbers. 
For example, if your table's read/write ratio is small, and it is expected to conform(따르다) to a Service Level Agreements (SLAs) for reads, it may be worth taking the write performance penalty of LCS / in order to keep read rates and latency at predictable levels. 
And you may be able to overcome this write penalty through horizontal scaling (adding more nodes).

`LCS는 SSTables를 예측 가능한 크기와 숫자 범위 내에서 유지합니다. `
예를 들어 테이블의 읽기/쓰기 비율이 작고 / 읽기용 SLA(Service Level Agreement)를 준수해야 하는 경우 / 읽기 속도와 지연 시간을 예측 가능한 수준으로 유지하려면 / LCS의 쓰기 성능 저하를 감수하는 것이 좋습니다. 
또한 수평 확장(노드 추가)을 통해 이러한 쓰기 취약성을 극복할 수 있습니다.

### Will your table be populated by a batch process?
On both batch reads and batch writes, STCS performs better than LCS. 
The batch process causes little or no fragmentation, so the benefits of LCS are not realized; batch processes can overwhelm LCS-configured tables.

배치 읽기 및 배치 쓰기 모두에서 `STCS는` LCS보다 `성능이 우수합니다`. 
배치 프로세스는 단편화를 거의 또는 전혀 일으키지 않으므로, LCS의 이점은 실현되지 않습니다. 배치 프로세스는 LCS 구성 테이블을 압도할 수 있습니다.

### Does your system have limited disk space?
LCS handles disk space more efficiently than STCS: it requires about 10% headroom / `in addition to(게다가, ~에 덧붙여)` the space occupied by the data is handles. 
STCS and DTCS generally require, in some cases, as much as 50% more than the data space.

`LCS는` STCS보다 `디스크 공간을 더 효율적으로 처리합니다.` 또한 데이터 핸들이 차지하는 공간 외에 / 약 10%의 헤드룸이 필요합니다. 
일반적으로 STC와 DTC는 데이터 공간보다 최대 50% 더 많은 양을 필요로 하는 경우도 있습니다.

### Is your system reaching its limits for I/O?
LCS is significantly more I/O intensive than `DTCS or STCS.` Switching to LCS may introduce extra I/O load that `offsets(상쇄하다)` the advantages.

LCS는 DICAT 또는 STCS보다 I/O 집약도가 월등히 높습니다. LCS로 전환하면 이점을 상쇄하는 추가 I/O 로드가 발생할 수 있습니다.

---

## Testing compaction strategies

Suggestions for determining which compaction strategy is best for your system:
    - Create a three-node cluster using one of the compaction strategies, stress test the cluster using cassandra-stress, and measure the results.
    - Set up a node on your existing cluster and use Cassandra's write survey mode to sample live data. See What’s new in Cassandra 1.1: live traffic sampling.

시스템에 가장 적합한 압축 전략을 결정하기 위한 제안:
    - 압축 전략 중 하나를 사용하여 3-노드 클러스터를 생성하고, 카산드라-스트레스를 사용하여 클러스터를 응력 테스트하고, 결과를 측정합니다.
    - 기존 클러스터에 노드를 설정하고 Cassandra의 쓰기 설문 모드를 사용하여 실시간 데이터를 샘플링합니다. Cassandra 1.1의 새로운 기능: 실시간 트래픽 샘플링을 참조하십시오.

## Configuring and running compaction
Set the compaction strategy for a table in the parameters for the CREATE TABLE or ALTER TABLE command. For details, see Table properties.

You can start compaction manually using the nodetool compact command.

## More information about compaction
The following blog posts and videos provide more information from developers that have tested compaction strategies:

When to Use Leveled Compaction
Leveled compaction in Apache Cassandra
Using TimeWindowCompactionStrategy for Time Series Workloads
DateTieredCompactionStrategy: Notes from the Field
Date-Tiered Compaction in Cassandra
DateTieredCompactionStrategy: Compaction for Time Series Data.
What delays a tombstone purge when using LCS in Cassandra

---
# 영단어
- tombstones(묘석,묘비)
- Over time 시간이 지남에 따라
- accumulate(모으다, 축적하다, 누적되다)
- retrieve(검색하다)
- periodically(주기적으로)
- performant (of technology, etc.) working in an effective way, 수행적인
- pending(보류중인, 미결인, 곧있을)
- as soon as ~하자마자
- free up : 확보하다, to make something available
- generalize 일반화하다
- intensive(집중적인) / intense 강렬한, 치열한
- initiate(개시하게 되다, 시작하다)
- accumulate(모으다, 축적하다)
- At any given time(언제든지)
- simultaneously(동시에)
- outstrip(앞지르다, 능가하다)

- intensive : 집약적인, 집중적인
- alleviates : 완화하다
- stale : 오래된
- overlapping : 중복된
- retrieve : 검색하다
- Obsolete : 더이상 쓸모없는
- portions : 부분
- out-of-sequence : 순서가 엉망으로
- overwhelmed : 압도된
- conform : 따르다
- offset : 상쇄하다

- upsert ; 업데이트시 만족하는 로우가 있으면 업데이트, 아니면 인서트